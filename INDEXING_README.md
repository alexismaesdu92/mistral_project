# ğŸ“š SystÃ¨me d'Indexation Vectorielle - Documentation Mistral AI

Ce systÃ¨me permet d'indexer automatiquement tous les fichiers markdown de la documentation Mistral AI dans une base vectorielle ChromaDB pour permettre des recherches sÃ©mantiques rapides et prÃ©cises.

## ğŸ—ï¸ Architecture

### Composants principaux

1. **`VectorService`** (`vector_service.py`)
   - Interface avec ChromaDB
   - Gestion des embeddings via l'API Mistral
   - OpÃ©rations CRUD sur les documents vectorisÃ©s

2. **`MarkdownChunker`** (`text_chunker.py`)
   - DÃ©coupage intelligent des documents markdown
   - PrÃ©servation du contexte (sections, titres)
   - Gestion du chevauchement entre chunks

3. **`DocumentIndexingService`** (`document_indexer.py`)
   - Orchestration de l'indexation
   - Gestion incrÃ©mentale (dÃ©tection des changements)
   - MÃ©tadonnÃ©es et statistiques

4. **Scripts utilitaires**
   - `index_documents.py` : Script principal d'indexation
   - `test_indexing.py` : Tests et validation

## ğŸš€ Installation et Configuration

### 1. Installer les dÃ©pendances

```bash
# Installer les dÃ©pendances du projet
pip install -e ".[dev]"

# Ou installer manuellement les dÃ©pendances principales
pip install chromadb tqdm beautifulsoup4 markdownify python-slugify
```

### 2. Configuration de l'API Mistral

CrÃ©ez un fichier `.env` Ã  la racine du projet :

```env
MISTRAL_API_KEY=votre_clÃ©_api_mistral
```

### 3. VÃ©rifier la structure des donnÃ©es

Assurez-vous que les fichiers markdown sont dans `data/scraping/` :

```
data/
â”œâ”€â”€ scraping/
â”‚   â”œâ”€â”€ docs.mistral.ai/
â”‚   â”‚   â”œâ”€â”€ index.md
â”‚   â”‚   â”œâ”€â”€ capabilities/
â”‚   â”‚   â”œâ”€â”€ guides/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ manifest.csv
â””â”€â”€ doc/  # Sera crÃ©Ã© automatiquement pour ChromaDB
```

## ğŸ”§ Utilisation

### Tests prÃ©liminaires

Avant la premiÃ¨re indexation, lancez les tests :

```bash
cd back_end/app
python test_indexing.py
```

### Indexation complÃ¨te

```bash
cd back_end/app

# PremiÃ¨re indexation (complÃ¨te)
python index_documents.py

# RÃ©indexation forcÃ©e de tous les fichiers
python index_documents.py --force

# Indexation incrÃ©mentale (seulement les fichiers modifiÃ©s)
python index_documents.py
```

### Test de recherche

```bash
# Rechercher dans les documents indexÃ©s
python index_documents.py --search "Mistral Large"
python index_documents.py --search "fine-tuning"
python index_documents.py --search "comment utiliser l'API"
```

### Statistiques

```bash
# Afficher les statistiques de l'index
python index_documents.py --stats
```

## ğŸ“Š FonctionnalitÃ©s

### DÃ©coupage intelligent

- **Par sections** : Respect de la hiÃ©rarchie markdown (H1, H2, H3...)
- **Taille optimale** : Chunks de ~1000 caractÃ¨res avec chevauchement de 200
- **Contexte prÃ©servÃ©** : Inclusion des titres de section et document
- **MÃ©tadonnÃ©es riches** : Fichier source, section, langue, type de contenu

### Indexation incrÃ©mentale

- **DÃ©tection des changements** : Hash SHA256 des fichiers
- **Mise Ã  jour sÃ©lective** : Seuls les fichiers modifiÃ©s sont rÃ©indexÃ©s
- **Gestion des suppressions** : Nettoyage automatique des anciens chunks
- **MÃ©tadonnÃ©es persistantes** : Suivi de l'Ã©tat d'indexation

### Recherche sÃ©mantique

- **Embeddings Mistral** : Utilisation du modÃ¨le `mistral-embed`
- **Recherche par similaritÃ©** : Scores de pertinence
- **MÃ©tadonnÃ©es contextuelles** : Informations sur la source des rÃ©sultats
- **RÃ©sultats enrichis** : Texte + contexte + mÃ©tadonnÃ©es

## ğŸ” Utilisation dans le code

### Recherche simple

```python
from services.document_indexer import DocumentIndexingService

# CrÃ©er le service
indexer = DocumentIndexingService()

# Rechercher
results = await indexer.search_documents("Comment utiliser Mistral Large?", n_results=5)

for result in results['result']:
    print(f"Score: {1 - result['distance']:.3f}")
    print(f"Texte: {result['text'][:200]}...")
    print(f"Source: {result.get('metadata', {}).get('source_file', 'Unknown')}")
```

### Utilisation directe du VectorService

```python
from services.vector_service import VectorService

# CrÃ©er le service vectoriel
vector_service = VectorService(collection_name='mistral_docs')

# Rechercher
results = await vector_service.search("fine-tuning Mistral", n_results=3)

# Ajouter un nouveau document
doc_id = await vector_service.add("Nouveau contenu Ã  indexer", "custom_doc_1")
```

## ğŸ“ Structure des fichiers gÃ©nÃ©rÃ©s

```
data/
â”œâ”€â”€ doc/                          # Base ChromaDB
â”‚   â”œâ”€â”€ chroma.sqlite3           # Base de donnÃ©es SQLite
â”‚   â”œâ”€â”€ index_metadata.json      # MÃ©tadonnÃ©es d'indexation
â”‚   â””â”€â”€ [uuid]/                  # Collections ChromaDB
â””â”€â”€ doc_test/                    # Base de test (crÃ©Ã©e par les tests)
```

### MÃ©tadonnÃ©es d'indexation

Le fichier `data/doc/index_metadata.json` contient :

```json
{
  "indexed_files": {
    "docs.mistral.ai/index.md": {
      "hash": "a218b79321fed0bf...",
      "chunk_ids": ["docs_mistral_ai_index_md_Bienvenue_to_Mistral_AI_Documentation_001", ...],
      "chunk_count": 15,
      "last_indexed": 1704067200.0
    }
  },
  "total_chunks": 1247,
  "last_update": 1704067200.0
}
```

## ğŸ¯ Optimisations et bonnes pratiques

### ParamÃ¨tres de chunking

```python
# Configuration recommandÃ©e pour la documentation
chunker = MarkdownChunker(
    chunk_size=1000,      # Taille optimale pour les embeddings
    chunk_overlap=200,    # Chevauchement pour prÃ©server le contexte
    min_chunk_size=100    # Ã‰viter les chunks trop petits
)
```

### Gestion de la mÃ©moire

- L'indexation traite les fichiers un par un
- Les embeddings sont gÃ©nÃ©rÃ©s par batch pour l'efficacitÃ©
- ChromaDB persiste automatiquement les donnÃ©es

### Performance

- **PremiÃ¨re indexation** : ~2-3 minutes pour ~50 fichiers
- **Indexation incrÃ©mentale** : ~10-30 secondes
- **Recherche** : ~100-200ms par requÃªte

## ğŸ› DÃ©pannage

### Erreurs communes

1. **"MISTRAL_API_KEY not set"**
   ```bash
   # VÃ©rifier le fichier .env
   cat .env
   # Ou exporter directement
   export MISTRAL_API_KEY="votre_clÃ©"
   ```

2. **"No markdown files found"**
   ```bash
   # VÃ©rifier la structure des donnÃ©es
   ls -la data/scraping/
   # Relancer le scraping si nÃ©cessaire
   ```

3. **Erreurs ChromaDB**
   ```bash
   # Supprimer et recrÃ©er la base
   rm -rf data/doc/
   python index_documents.py --force
   ```

### Logs et debugging

```python
# Activer les logs dÃ©taillÃ©s
import logging
logging.basicConfig(level=logging.DEBUG)

# Ou utiliser le mode verbose dans les scripts
python index_documents.py --force  # Affiche plus de dÃ©tails
```

## ğŸ”„ IntÃ©gration avec le chatbot

Le systÃ¨me d'indexation s'intÃ¨gre parfaitement avec votre `MistralService` :

```python
# Dans votre chatbot
from services.document_indexer import DocumentIndexingService

class EnhancedMistralService(MistralService):
    def __init__(self):
        super().__init__()
        self.indexer = DocumentIndexingService()
    
    async def generate_response_with_context(self, prompt: str):
        # Rechercher du contexte pertinent
        context_results = await self.indexer.search_documents(prompt, n_results=3)
        
        # Construire le prompt avec contexte
        context = "\n".join([r['text'] for r in context_results['result']])
        enhanced_prompt = f"Contexte:\n{context}\n\nQuestion: {prompt}"
        
        # GÃ©nÃ©rer la rÃ©ponse
        return await self.generate_response(enhanced_prompt)
```

## ğŸ“ˆ Prochaines amÃ©liorations

- [ ] Interface web pour la gestion de l'index
- [ ] Support de formats additionnels (PDF, HTML)
- [ ] Recherche hybride (mots-clÃ©s + sÃ©mantique)
- [ ] Mise Ã  jour en temps rÃ©el via webhooks
- [ ] MÃ©triques et analytics de recherche
